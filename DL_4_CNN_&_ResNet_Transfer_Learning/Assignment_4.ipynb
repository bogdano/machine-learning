{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04drDbxf7OaY"
   },
   "source": [
    "# Convolutional Neural Networks for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaV4CZH67Z1W"
   },
   "source": [
    "## *Bogdan Bošković*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwSTtOHG6rEM"
   },
   "source": [
    "**Introduction.**  In this exercise you will utilize convolutional neural networks to solve problems in computer vision, such as image classification, object detection, and segmentation.  \n",
    "\n",
    "**Instructions.** As usual, please submit your code and its output as a pdf file, generated from a Jupyter notebook.  I recommend you complete this assignment in Google CoLab [(link)](https://colab.research.google.com/), but it is also certainly possible to complete it in a local IDE if you first install pytorch (instructions not included here).  The assignment will be divided into \"Problems\", which will be indicated below along with the number of points awarded for completion.  We will begin the assignment by importing important libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG_C0K7ye946"
   },
   "source": [
    "## **PROBLEM 1 (40 Total Points)**\n",
    "\n",
    "**Part (a) (10 points)**\n",
    "You will begin this problem by setting up a baseline neural network model, and helper functions, that you developed in the last assignment.  Therefore this first part will mostly involve running code that I provide to you here, or utilizing code that you developed in the previous assignment.  Start by importing the software libraries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "osxUdcBK6m41"
   },
   "outputs": [],
   "source": [
    "# You will need the following libraries to complete the assignment\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cCi59hj6itA"
   },
   "source": [
    "**Now load the MNIST Data**, along with built-in PyTorch data loaders. Run the following code to load the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I_LgnpFEI54u"
   },
   "outputs": [],
   "source": [
    "# Fill in the details for the \"transform\" variable\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.05), (0.05))])\n",
    "\n",
    "# We will use a relatively large batch size of 128 here to\n",
    "#  accelerate the training process\n",
    "batch_size = 128\n",
    "\n",
    "# Download the MNIST dataset and data loaders\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Label the classes\n",
    "classes = ('zero', 'one', 'two', 'three',\n",
    "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UvA1OKe68ps"
   },
   "source": [
    "**Construct a Baseline Model**.  Our baseline model will be a fully-connected neural network with 8 total layers of parameters.  Aside from the output layer, each layer has 50 hidden units, with ReLU activations.  We will call this network *NetFC*.  Note that this is simply the first model that you were asked to create in the previous assignment, however I have provided the code for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N7vSzXfR1rgg"
   },
   "outputs": [],
   "source": [
    "class NetFc(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.fc1 = nn.Linear(28*28, 50)\n",
    "      self.fc2 = nn.Linear(50, 50)\n",
    "      self.fc3 = nn.Linear(50, 50)\n",
    "      self.fc4 = nn.Linear(50, 50)\n",
    "      self.fc5 = nn.Linear(50, 50)\n",
    "      self.fc6 = nn.Linear(50, 50)\n",
    "      self.fc7 = nn.Linear(50, 50)\n",
    "      self.fc8 = nn.Linear(50, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = torch.flatten(x, 1)\n",
    "      x1 = F.relu(self.fc1(x))\n",
    "      x2 = F.relu(self.fc2(x1))\n",
    "      x3 = F.relu(self.fc3(x2))\n",
    "      x4 = F.relu(self.fc4(x3))\n",
    "      x5 = F.relu(self.fc5(x4))\n",
    "      x6 = F.relu(self.fc6(x5))\n",
    "      x7 = F.relu(self.fc7(x6))\n",
    "\n",
    "      output = self.fc8(x5)\n",
    "\n",
    "      # Return the output of the network\n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNCR_SJO4mGg"
   },
   "source": [
    "**Import Helper Functions** In the last assignment you were required to create two functions: *trainMyModel* and *testMyModel*.  You will need to re-use these functions again here and you can paste them here and run them.  To keep the notebook a little cleaner, I import these two functions from another python file called *dl_assignment4_helper_functions*, below.  I use the prefix *hlp* to call these functions. It is up to you whether you paste these functions into the notebook, or import them.  However, note that the code skeletons below assume that they are imported with the *hlp* prefix, and you will have to remove/modify the prefix if you don't import them in a similar fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WXfEF1p22SfI"
   },
   "outputs": [],
   "source": [
    "import dl_assignment4_helper_functions as hlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IDnDlo9pF1I"
   },
   "source": [
    "**Train and Test the Baseline Model** Now Run your *NetFC* model using a learning rate of 0.01 for 2 epochs.  These values are chosen because they work relatively well.  This model should usually achieve around 94% accuracy, and this will serve as our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7_1Y-ZBapyno"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "[epoch: 1, batch: 100] loss: 0.731\n",
      "[epoch: 1, batch: 200] loss: 0.325\n",
      "[epoch: 1, batch: 300] loss: 0.269\n",
      "[epoch: 1, batch: 400] loss: 0.257\n",
      "[epoch: 2, batch: 100] loss: 0.260\n",
      "[epoch: 2, batch: 200] loss: 0.230\n",
      "[epoch: 2, batch: 300] loss: 0.243\n",
      "[epoch: 2, batch: 400] loss: 0.195\n",
      "✨ Finished Training ✨\n"
     ]
    }
   ],
   "source": [
    "# Train your model.\n",
    "net = NetFc();\n",
    "lr = 0.01;\n",
    "n_epochs = 2;\n",
    "trainedNet = hlp.trainMyModel(net,lr,trainloader,n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X1Tt5C2eotyo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.4 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your model\n",
    "hlp.testMyModel(trainedNet,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOwGih9UWpDG"
   },
   "source": [
    "**Part (b) (20 points)** Now we will see the advantages of convolutional structures in a deep neural network.  Below, fill in the template to create convolutional neural network, called 'NetCnn' that has the following structure:\n",
    "\n",
    "layer1: 8 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
    "\n",
    "layer2: 16 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
    "\n",
    "layer3: 2x2 max pooling, with stride of 2. No zero-padding.\n",
    "\n",
    "layer4: 32 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
    "\n",
    "layer5: 64 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
    "\n",
    "layer6: 2x2 max pooling, with stride of 2. No zero-padding.\n",
    "\n",
    "layer7: a fully connected layer of 50 neurons.\n",
    "\n",
    "Layer8: a fully connected layer of 10 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_utdBDaOW0VN"
   },
   "outputs": [],
   "source": [
    "# Convolutional model - adding in convolutional layers\n",
    "\n",
    "class NetCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      # input channels = 1 because MNIST images are 1D\n",
    "      self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=1, stride=1)\n",
    "      # in_channels = 8 because 8 output channels from previous layer\n",
    "      self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=1, stride=1)\n",
    "      self.pool3 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0)\n",
    "      self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1, stride=1)\n",
    "      self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1, stride=1)\n",
    "      self.pool6 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0)\n",
    "\n",
    "      # 1x1 convolution to match channels of layer 1 with layer 4, for skip to 5\n",
    "      self.channel_match = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1)\n",
    "\n",
    "      # fully connected layer with 50 neurons -- 64 is the number of output channels, \n",
    "      # 7x7 are the dimensions of the image after two max pooling layers\n",
    "      self.fc7 = nn.Linear(in_features=64*7*7, out_features=50)\n",
    "      # fully connected layer with 10 neurons = 10 classes\n",
    "      self.fc8 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x1 = F.relu(self.conv1(x))\n",
    "      x2 = F.relu(self.conv2(x1))\n",
    "      x3 = self.pool3(x2)\n",
    "      x4 = F.relu(self.conv4(x3))\n",
    "\n",
    "      # upsample x2 to mactn dimensions of x5\n",
    "      x2_up = F.interpolate(x2, size=(x4.size(2), x4.size(3)), mode='nearest')\n",
    "      # match the number of channels in x5 (run through 1x1 conv from init)\n",
    "      x2_matched = self.channel_match(x2_up)\n",
    "      \n",
    "      # skip connection from layer 2 to layer 4\n",
    "      x5 = F.relu(self.conv5(x4 + x2_matched))\n",
    "      x6 = self.pool6(x5)\n",
    "      # flatten the tensor for fully connected layer\n",
    "      x6 = torch.flatten(x6, 1)\n",
    "      x7 = F.relu(self.fc7(x6))\n",
    "      output = self.fc8(x7)\n",
    "      # return output of model\n",
    "      return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6z-CbzUyjOK"
   },
   "source": [
    "Now train the model for 2 epochs using your *trainMyModel* function, which should report the loss every 100 iterations, as was requested in the last assignment.  Then, using *testMyModel* function, evaluate the accuracy of your trained model on the test set. If done correctly, you should obtain around 97% accuracy on the testing set, a relatively significant improvement over *NetFc* if you consider how much error remains.  Note that you may need to tune the learning rate a little bit to achieve this level of accuracy.  \n",
    "\n",
    "Not that we could add skip connections to 'NetCnn' as well, which would further improve its performance, but this is a little tricky and it will not be part of this assignment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "e9syyinWW4cV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch: 100] loss: 0.504\n",
      "[epoch: 1, batch: 200] loss: 0.131\n",
      "[epoch: 1, batch: 300] loss: 0.100\n",
      "[epoch: 1, batch: 400] loss: 0.092\n",
      "[epoch: 2, batch: 100] loss: 0.094\n",
      "[epoch: 2, batch: 200] loss: 0.081\n",
      "[epoch: 2, batch: 300] loss: 0.071\n",
      "[epoch: 2, batch: 400] loss: 0.083\n",
      "✨ Finished Training ✨\n",
      "Accuracy of the network on the 10000 test images: 98.08 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.08"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your model.\n",
    "net = NetCnn()\n",
    "lr = 0.01\n",
    "n_epochs = 2\n",
    "\n",
    "trainedNet = hlp.trainMyModel(net,lr,trainloader,n_epochs)\n",
    "\n",
    "# Test your model\n",
    "hlp.testMyModel(trainedNet,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL6PM6bvyn9E"
   },
   "source": [
    "**Part (c) (10 points)**  Compute the number of parameters in the NetFC model and the NetCnn model, respectively, as described in UDL.  Please show your work, and then report your final answer in scientific notation $x \\times 10^y$ where you need to fill in $x$ and $y$.  You need only report $x$ reported to one decimal place, and $y$ should be an integer.  You will be primarily graded on a correct order of magnitude, $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "**Part (c):**\n",
    "\n",
    "The number of parameters in a fully connected layer is:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters} = \\text{previous layer} \\times \\text{current layer} + \\text{current layer}\n",
    "$$\n",
    "\n",
    "So, in the NetFC model, we have:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters} = 784\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters 1st layer} = 50 \\times 784 + 50 = 39200\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters 2nd layer} = 50 \\times 50 + 50 = 2550\n",
    "$$\n",
    "\n",
    "Subsequent layers have the same number of parameters, except for the output layer, which has 10 neurons. So, the number of parameters in the NetFC model over the first 7 layers is:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters 1-7} = 2550 \\times 6 + 39200 = 54500\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters 1-8} = 54500 + 50 \\times 10 + 10 = 55010\n",
    "$$\n",
    "\n",
    "Now, the number of parameters in a convolutional layer is:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters} = \\text{number of filters} \\times \\text{channels in previous layer} \\times \\text{filter} + \\text{number of filters}\n",
    "$$\n",
    "\n",
    "So, for the NetCnn model, we have:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters layer 1} = 8 \\times 1 \\times 3 \\times 3 + 8 = 80\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters layer 2} = 16 \\times 8 \\times 3 \\times 3 + 16 = 1168\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters layer 4} = 32 \\times 16 \\times 3 \\times 3 + 32 = 4640\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters layer 5} = 64 \\times 32 \\times 3 \\times 3 + 64 = 18464\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters layer 7} = 64 \\times 7 \\times 7 \\times 50 + 50 = 164200\n",
    "$$\n",
    "$$\n",
    "\\text{Number of parameters layer 8} = 50 \\times 10 + 10 = 510\n",
    "$$\n",
    "\n",
    "So, the total number of parameters in the NetCnn model is:\n",
    "\n",
    "$$\n",
    "\\text{Number of parameters NetCnn} = 80 + 1168 + 4640 + 18496 + 157850 + 510 = 189062\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlZ7JHZ2WvqF"
   },
   "source": [
    "**Part (d) (10 POINTS)**  In this last subproblem, you will add batch normalization layers to your network.  Batch normalization, and its variants (e.g., \"layer norm\") are another structure that is now widely-used in modern deep neural networks.  In this problem you will design a neural network called *NetCnnBn* with the exact same structure as 'NetCnn' except you will add two batch normalization layers in the following locations: (i) after the 2nd convolutional layer, and (ii) after the 1st fully connected layer.  \n",
    "\n",
    "Train your NetCnnBn for 2 epochs using your *trainMyModel* function, and then report its accuracy on the test set using the *testMyModel* function.  If done properly, you should be now be able to achieve approximately 99% accuracy on the testing dataset after two epochs of training.  NOte that you may need to adjust the learning rate again.  Despite this significant performance improvement, note that batch normalization contributes a very small number of parameters.  In our case, for example, it adds $<200$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Q2UECtlqXIa0"
   },
   "outputs": [],
   "source": [
    "# Convolutional model - adding in batch norm\n",
    "class NetCnnBn(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      # input channels = 1 because MNIST images are 1D\n",
    "      self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=1, stride=1)\n",
    "      # in_channels = 8 because 8 output channels from previous layer\n",
    "      self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=1, stride=1)\n",
    "      # adding batch normalization, num_features = 16 because 16 output channels from previous layer\n",
    "      self.bn3 = nn.BatchNorm2d(num_features=16)\n",
    "      self.pool4 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0)\n",
    "\n",
    "      # 1x1 convolution to match channels of conv2 with conv5, for skip to conv6\n",
    "      self.channel_match = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1)\n",
    "\n",
    "      self.conv5 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1, stride=1)\n",
    "      self.conv6 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1, stride=1)\n",
    "      self.pool7 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0)\n",
    "      # fully connected layer with 50 neurons -- 64 is the number of output channels, \n",
    "      # 7x7 are the dimensions of the image after two max pooling layers\n",
    "      self.fc8 = nn.Linear(in_features=64*7*7, out_features=50)\n",
    "      # batch normalization\n",
    "      self.bn9 = nn.BatchNorm1d(num_features=50)\n",
    "      # fully connected layer with 10 neurons = 10 classes\n",
    "      self.fc10 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x1 = F.relu(self.conv1(x))\n",
    "      x2 = F.relu(self.conv2(x1))\n",
    "      x3 = self.bn3(x2)\n",
    "      x4 = self.pool4(x3)\n",
    "      x5 = F.relu(self.conv5(x4))\n",
    "\n",
    "      # upsample x2 to match dimensions of x5\n",
    "      x2_up = F.interpolate(x2, size=(x5.size(2), x5.size(3)), mode='nearest')\n",
    "      # match the number of channels in x5 (run through 1x1 conv from init)\n",
    "      x2_matched = self.channel_match(x2_up)\n",
    "\n",
    "      # skip connection from layer 2 to layer 5\n",
    "      x6 = F.relu(self.conv6(x5 + x2_matched))\n",
    "      x7 = self.pool7(x6)\n",
    "      # flatten the tensor for fully connected layer\n",
    "      x8 = torch.flatten(x7, 1)\n",
    "      x9 = F.relu(self.fc8(x8))\n",
    "      x10 = self.bn9(x9)\n",
    "      output = self.fc10(x10)\n",
    "      # return output of model\n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "8qRKLcO0XFZ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch: 100] loss: 0.266\n",
      "[epoch: 1, batch: 200] loss: 0.079\n",
      "[epoch: 1, batch: 300] loss: 0.062\n",
      "[epoch: 1, batch: 400] loss: 0.054\n",
      "[epoch: 2, batch: 100] loss: 0.055\n",
      "[epoch: 2, batch: 200] loss: 0.045\n",
      "[epoch: 2, batch: 300] loss: 0.046\n",
      "[epoch: 2, batch: 400] loss: 0.042\n",
      "✨ Finished Training ✨\n",
      "Accuracy of the network on the 10000 test images: 98.99 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.99"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your model.\n",
    "net = NetCnnBn()\n",
    "lr = 0.01\n",
    "n_epochs = 2\n",
    "\n",
    "trainedNet = hlp.trainMyModel(net,lr,trainloader,n_epochs)\n",
    "\n",
    "# Test your model\n",
    "hlp.testMyModel(trainedNet,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiJygNt6wTO7"
   },
   "source": [
    "## **PROBLEM 2 (20 Total Points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-aul15FwWtD"
   },
   "source": [
    "In this problem you will investigate transfer learning.  Load in a resnet18 model, and initialize its training with weights that were pre-trained on the ImageNet dataset.  Call this model *pretrainedResNet* As a hint, you cannot simply apply a pre-trained resnet18 to this problem; you will need to make two changes to the model structure for it to work properly.  \n",
    "\n",
    "Once you have made the proper modifications (fill in code below), train and test your model on the MNIST data, as you have done with previous models.  If done properly, you should only require a few lines of code, and you should usually obtain around 97% accuracy with 1 epoch of training and the learning rate provided below (lr = 0.0001).  You only need to show your results with these settings. Unfortunately the MNIST dataset is not ideal for demonstrating the tremendous benefits of transfer learning, but this exercise will help familiarize you with the process of adapting pre-trained models to a custom task, which is important in practice.   \n",
    "\n",
    "For this problem I highly recommend that you use a GPU because training will be  relatively slow without it (e.g., a couple minutes for 1 epoch, depending upon your hardware).  With a GPU the training should generally run very quickly, finishing in under 30 seconds or less.  Note that you can procure a free GPU to use on Google Colab, however, you are given a limited GPU compute per day unless you pay. Consequently I strongly recommend that you debug on a CPU before deploying onto the GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "7LSH38QUwaXS"
   },
   "outputs": [],
   "source": [
    "# Please load a pre-trained resnet-18 model and make the necessary changes so that it will work on the MNIST problem\n",
    "\n",
    "# load the pre-trained model\n",
    "preTrainedResNet = torchvision.models.resnet18(pretrained=True)\n",
    "# change input layer to accept 1 channel\n",
    "preTrainedResNet.conv1 = nn.Conv2d(1, 64, kernel_size=1)\n",
    "# change output layer to have 10 classes\n",
    "preTrainedResNet.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ClZUrjOjwdVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "[epoch: 1, batch: 100] loss: 0.754\n",
      "[epoch: 1, batch: 200] loss: 0.208\n",
      "[epoch: 1, batch: 300] loss: 0.150\n",
      "[epoch: 1, batch: 400] loss: 0.116\n",
      "✨ Finished Training ✨\n",
      "Accuracy of the network on the 10000 test images: 96.99 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.99"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test your model\n",
    "lr = 0.0001;\n",
    "n_epochs = 1;\n",
    "trainedNet = hlp.trainMyModel(preTrainedResNet,lr,trainloader,n_epochs);\n",
    "\n",
    "hlp.testMyModel(trainedNet,testloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJDzS8lL1vi5AhxjycIi9q",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
